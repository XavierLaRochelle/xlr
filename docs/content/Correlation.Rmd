---
title: "Corrélation"
author: "Xavier La Rochelle"
date: "`r Sys.Date()`"
output: 
  html_document:
    toc: true
    toc_float: true
    number_section: true
    theme: readable
---

---

```{r setup, include=FALSE}
# Packages
library(knitr)
library(readr)
library(tibble)
library(sjmisc)
library(jmv)
library(ggplot2)

# Importer les données
donnees_brutes <- read_csv("../data/data_visualisation.csv") 

# Préparer les données 
df <- tibble(id = 1:nrow(donnees_brutes))
df$symptomesDepressifs <- donnees_brutes$CESD_PreTotal
df$emotionPositive <- donnees_brutes$PANAS_Pos_Pre
```

***Important :*** Ce guide assume que vous savez comment :  

1. [Rédiger un script RMarkdown](../content/script_rmarkdown.html)  
2. [Installer et activer des packages](../content/packages.html)  
3. [Importer une base de données](../content/importer_les_donnees.html)
4. [Préparer des données](../content/preparer_les_donnees.html)

Vous pouvez cliquer sur les liens ci-dessus pour consulter les guides associées. 

---

## Importer et préparer les données  
Dans ce guide, nous utiliserons deux variables du fichier `data_visualisation.csv`, soit les symptômes dépressifs (`symptomesDepressif`) et les émotions positives (`emotionPositive`). Pour vous évitez de tout re-coder, j'ai pris le temps d'écrire la syntaxe nécessaire pour importer et préparer les données : 
```{r, eval=FALSE}
# Packages
library(readr)
library(tibble)
library(ggplot2)

# Importer les données (data_visualisation.csv)
donnees_brutes <- read_csv("folder path")  

# Préparer les données 
df <- tibble(id = 1:nrow(donnees_brutes))
df$symptomesDepressifs <- donnees_brutes$CESD_PreTotal
df$emotionPositive <- donnees_brutes$PANAS_Pos_Pre
```

Pour suivre les exemples dans ce guide, vous devrez donc :  
1. avoir téléchargé le fichier `data_visualisation.csv` sur Studium  
2. noter le `"folder path"`  
3. exécuter la syntaxe ci-dessus (en changeant le `"folder path"`). 

Voici à quoi devrait ressembler votre banque de données après l'étape de préparation :
```{r}
df
```

# Corrélation de Pearson
Ce guide décrit comment calculer la corrélation de Pearson entre deux variables continues. 

Pour obtenir uniquement la corrélation, il est possible d'utiliser la fonction `cor()` du package R de base :  
```{r}
cor(df$symptomesDepressifs, df$emotionPositive)
```

Dans ce cas-ci, on observe une corrélation négative (*r* ≈ -,24) entre les symptômes dépressifs et les émotions positives (qui l'eut cru!). Les deux arguments nécessaires à cette fonction (`x` et `y`) désigne simplement les deux variables dont on souhaite investiguer l'association (dans ce cas-ci, `df$symptomesDepressifs` et `df$emotionPositive`). L'ordre n'a pas d'importance.

## Test d'hypothèse bilatérale
La fonction `cor()` ne vous permet pas de vérifier si la corrélation observée est significative. Pour ce faire, vous devrez utiliser la fonction `cor.test()`, qui est dans le package `stats` (installé par défaut dans R). Cette fonction vous permettra d'obtenir la valeur de p (`p-value`) d'une corrélation et ainsi vérifier la significativité de la corrélation observée (en comparant la valeur de p à votre seuil alpha critique). Voici la syntaxe :  
```{r}
cor.test(df$symptomesDepressifs, df$emotionPositive,
         alternative = "two.sided")
```
Dans cet exemple, on voit que la corrélation entre les symtpômes dépressifs et les émotions positives est négative et significative (*r* ≈ -,24; *p* < ,05).

Comme pour la méthode précédente, les deux premiers arguments (`df$symptomesDepressifs` et `df$emotionPositive`) désigne simplement les deux variables (`x` et `y`) dont on souhaite investiguer l'association. Le dernier argument (`alternative =`) désigne la direction du test d'hypothèse que l'on pose. Pour une hypothèse bilatérale (corrélation positive ou négative), vous devez indiquer `"two.sided"`, comme dans l'exemple ci-dessus. 

## Test d'hypothèse unilatérale
Pour poser l'hypothèse d'une corrélation supérieure ou inférieure à 0, vous pouvez indiquer `"greater"` et `"less"` respectivement à l'argument `alternative =`. Par exemple :  
```{r}
cor.test(df$symptomesDepressifs, df$emotionPositive,
         alternative = "less")
```
Comme on peut le constater, la corrélation est toujours négative, mais la valeur de *p* est désormais plus petite (*r* ≈ -,24; *p* < ,01). Cela est dû au fait que, lorsqu'on pose une hypothèse unilatérale, on ne considère qu'une seule queue de la distribution *t* plutôt que les deux.

# Corrélation de Spearman
La fonction `cor()` du package R de base permet aussi d'obtenir la corrélation de Spearman à condition de spécifier `"spearman"` dans l'argument `method = ` comme ceci :  
```{r}
cor(df$symptomesDepressifs, df$emotionPositive,
    method = "spearman")
```

Celle-ci est légèrement plus faible que la corrélation de Pearson obtenu précédemment.

## Homoscédasticité
La corrélation de Spearman est plus appropriés que la corrélation de Pearson lorsque les données ne sont pas homoscédastiques (c.-à-d. que les observations ne sont pas distribuées de façon homogènes). On peut vérifier l'homoscédasticité à l'aide d'un diagramme de dispersion : 
```{r}
library(ggplot2)
ggplot(df, aes(x = symptomesDepressifs, y = emotionPositive)) +
    geom_point() + 
    labs(x = "Symptômes dépressifs", y = "Émotions positives") +
    theme_classic()
```

On peut observer la légère tendance inverse que se reflètait dans la corrélation de Pearson : les observations avec de plus hauts niveaux de symptômes dépressifs ont de plus faible niveaux d'émotions positives (et vis-versa). Au niveau de l'homoscédasticité, on pourrait argumenter que l'homogénéité de cette distribution n'est pas adéquate, surtout en comparant les niveaux faibles et élevés de symtpômes dépressifs.

## Test d'hypothèse
La fonction présenté pour tester la corrélation de Pearson fonctionne également pour la corrélation de Spearman. Il faut simplement assigner `Spearman` à l'argument `method =` comme ceci :
```{r}
cor.test(df$symptomesDepressifs, df$emotionPositive,
         alternative = "two.sided",
         method = "spearman")
```
*Note* : l'avertissement « *Cannot compute exact p-value with ties* » est normal. Il indique simplement qu'une méthode d'approximation a été utilisée pour obtenir la valeur de p puisque certaines observations obtiennent le même rang. 