---
title: "ANOVA"
author: "Xavier La Rochelle"
date: "`r Sys.Date()`"
output: 
  html_document:
    toc: true
    toc_float: true
    number_section: true
    theme: readable
---

```{css, echo=F}
pre code {
  white-space: pre;
}
```

```{r setup, include=FALSE}
# Packages
library(knitr)
library(tibble)
library(ggplot2)
library(car)
library(effectsize)
library(emmeans)

# Importer les données
data("iris")
df <- tibble(iris)
```

***Important :*** Ce guide assume que vous savez comment :  

1. [Rédiger un script RMarkdown](../content/script_rmarkdown.html)  
2. [Installer et activer des packages](../content/packages.html)  
3. [Importer une base de données](../content/importer_les_donnees.html)
4. [Préparer des données](../content/preparer_les_donnees.html)
5. [Vérifier la normalité](../content/test-t.html) (Section 1.1)

Vous pouvez cliquer sur les liens ci-dessus pour consulter les guides associées. 

## Banque de données

Dans ce guide, nous étudierons des fleurs. La banque de données que nous utiliserons (`iris`) est inclue par défaut dans R. Pour suivre, vous n'avez donc qu'à utiliser la syntaxe suivante :  

```{r, eval=FALSE}
# Packages
library(knitr)
library(tibble)
library(ggplot2)
library(car)
library(effectsize)
library(emmeans)

# Importer les données
data("iris")
df <- tibble(iris)
```


Voici à quoi devrait ressembler votre banque de données après l'étape de préparation :
```{r}
df
```


---

# ANOVA

---

## Hypothèses

L'hypothèse alternative est qu'il existe au moins une distribution dont la moyenne s'écarte des autres moyennes : 
$$ 
\begin{aligned}
H_0 & : \mu_1 = \mu_2 = \mu_3 = \mu \\
H_1 &: \exists(i,j) \: \text{tel que} \: \mu_i ≠ \mu_j \\
\end{aligned}
$$ 
*Note*: l'hypothèse $H_1$ se traduit comme suit : « *Il existe une combinaison de i et j tel que la moyenne $\mu_i$ n'est pas égale à la moyenne $\mu_j$ *» (*shoutout* à [cet article wikipedia](https://fr.wikipedia.org/w/index.php?title=Analyse_de_la_variance)). Autrement dit, une ANOVA significative nous indique qu'au moins une des affirmations suivantes est vraie :  
$$
\begin{aligned}
\mu_{\text{setosa}} & ≠ \mu_{\text{versicolor}} \\
\mu_{\text{setosa}}  & ≠  \mu_{\text{virginica}}\\
\mu_{\text{versicolor}}  & ≠  \mu_{\text{virginica}}\\
\end{aligned}
$$

Voici un graphique pour visualiser l'analyse que nous allons effectuer : 

```{r}
ggplot(df, aes(x = Petal.Length, fill = Species)) + 
    geom_density(alpha = .5) +
    geom_vline(lty = 2, col = "red", xintercept = mean(df[df$Species == "setosa",]$Petal.Length)) +
    geom_vline(lty = 2, col = "green", xintercept = mean(df[df$Species == "versicolor",]$Petal.Length)) +
    geom_vline(lty = 2, col = "blue", xintercept = mean(df[df$Species == "virginica",]$Petal.Length)) +
    labs(x = "Longeur du sépale", y = "Densité") + 
    theme_classic()
```

---

## Postulats

1. La variable est continue : ☑  
2. Les observations sont indépendantes : ☑
3. Distribution normale dans chaque groupe : à vérifier  
4. Homoscédasticité : à vérifier

```{r}
df_setosa <- subset(df, df$Species == "setosa")
df_versicolor <- subset(df, df$Species == "versicolor")
df_virginica <- subset(df, df$Species == "virginica")
```


---

### Normalité 

#### Shapiro-Wilk

```{r}
shapiro.test(df_setosa$Petal.Length)
shapiro.test(df_versicolor$Petal.Length)
shapiro.test(df_virginica$Petal.Length)
```

---

#### QQplot

```{r}
qqnorm(df_setosa$Petal.Length)
qqline(df_setosa$Petal.Length)
```

```{r}
qqnorm(df_virginica$Petal.Length)
qqline(df_virginica$Petal.Length)
```

```{r}
qqnorm(df_versicolor$Petal.Length)
qqline(df_versicolor$Petal.Length)
```

---

### Homoscédasticité

```{r, message=FALSE}
library(car)
leveneTest(df$Petal.Length ~ df$Species)
```

---

## Faire le test

```{r}
model <- lm(Petal.Length ~ Species, data = df)
anova(model)
```

On peut conclure que la longueur moyennes des pétales diffère significativement selon l'espèce de fleur ($F(2,147) = 1180,2; p < ,05$).

---

## Calculer la taille d'effet
```{r}
library(effectsize)
eta_squared(model)
cohens_f(model)
```

---

## Tests post-Hoc

```{r}
library(emmeans)
emmeans(model, tukey ~ Species)
```

---

# Test de Kruskal-Wallis
Le test de Kruskal-Wallis est souvent présenté comme une version « robuste » de l'ANOVA et constitue une généralisation du Test U Mann-Whitney (voir section 2 du guide `test-t.html`). 

---

## Postulats
Voici les postulats du test de Kruskal-Wallis :  

1. La variable est continue : ☑  
2. Les observations sont indépendantes : ☑

---

## Faire le test
```{r}
kruskal.test(df$Petal.Length ~ df$Species)
```

On peut encore une fois conclure que la longueur moyenne des pétales diffère significativement selon l'espèce de fleur ($\chi^2(2) = 130,4; p < ,05$). 

---

## Tests post-Hoc
```{r}
pairwise.wilcox.test(df$Petal.Length, df$Species, 
                     p.adjust.method = "bonferroni")
```
*Note*: Le critère d'ajustement de la valeur de p de Tukey n'est pas disponible pour cette méthode. J'utilise donc la méthode de correction de Bonferroni. D'autres méthodes sont disponibles. Pour les consulter, exécuter le code suivant dans la console : `?p.adjust.methods`

Le test post-hoc avec correction de Bonferroni indique que toutes les différences sont significatives ($p < ,05$).